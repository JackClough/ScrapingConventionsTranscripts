{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assingment we'll scrape the Democratic and Republican national conventions, thanks to transcripts created by Rev, a company that builds transcripts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests               # To get the pages\n",
    "from bs4 import BeautifulSoup # and to process them\n",
    "\n",
    "from time import sleep      # Allowing us to pause between pulls\n",
    "from random import random   # And allowing that pause to be random\n",
    "\n",
    "import textwrap             # Useful for our wrapped output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our purposes, we'll just work with the visible text, so let's grab that function. We'll also want to have the function that makes a nice filename for us. You'll need to fill in that filename function, but I've given you the code in an exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4.element import Comment\n",
    "\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def generate_filename_from_url(url) :\n",
    "    \n",
    "    # Put code here from scraping exercise\n",
    "    if not url :\n",
    "        return None\n",
    "    \n",
    "    # drop the http or https\n",
    "    name = url.replace(\"https\",\"\").replace(\"http\",\"\")\n",
    "\n",
    "    # Replace useless chareacters with UNDERSCORE\n",
    "    name = name.replace(\"://\",\"\").replace(\".\",\"_\").replace(\"/\",\"_\").replace(\"-\", \"_\")\n",
    "    \n",
    "    # remove last underscore\n",
    "    last_underscore_spot = name.rfind(\"_\")\n",
    "    \n",
    "    name = name[:last_underscore_spot] + name[(last_underscore_spot+1):]\n",
    "\n",
    "    # tack on .txt\n",
    "    name = name + \".txt\"\n",
    "    \n",
    "    return(name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jack - Create a dictionary and fill it with two keys, \"democrats\" and \"republicans\". Each key will have four values,\n",
    "#which will be the urls.\n",
    "\n",
    "convention_pages = dict()\n",
    "\n",
    "convention_pages[\"democrats\"] = \"\"\"\n",
    "https://www.rev.com/blog/transcripts/democratic-national-convention-dnc-night-1-transcript\n",
    "https://www.rev.com/blog/transcripts/democratic-national-convention-dnc-2020-night-2-transcript\n",
    "https://www.rev.com/blog/transcripts/democratic-national-convention-dnc-night-3-transcript\n",
    "https://www.rev.com/blog/transcripts/2020-democratic-national-convention-dnc-night-4-transcript\n",
    "\"\"\".split()\n",
    "\n",
    "convention_pages[\"republicans\"] = \"\"\"\n",
    "https://www.rev.com/blog/transcripts/2020-republican-national-convention-rnc-night-1-transcript\n",
    "https://www.rev.com/blog/transcripts/2020-republican-national-convention-rnc-night-2-transcript\n",
    "https://www.rev.com/blog/transcripts/2020-republican-national-convention-rnc-night-3-transcript\n",
    "https://www.rev.com/blog/transcripts/2020-republican-national-convention-rnc-night-4-transcript\n",
    "\"\"\".split()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some questions to answer as part of the assignment: \n",
    "\n",
    "1. What kind of object is `convention_pages`? \n",
    "1. What kind of object is `convention_pages[\"republicans\"]`? \n",
    "\n",
    "Now your answers: \n",
    "\n",
    "1. A dictionary\n",
    "1. A list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through these pages and scrape all visible text. We'll store each text in its own\n",
    "file where the file name is the last part of the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for 10.70 seconds.\n",
      "Waiting for 7.50 seconds.\n",
      "Waiting for 14.00 seconds.\n",
      "Waiting for 5.82 seconds.\n",
      "Waiting for 9.49 seconds.\n",
      "Waiting for 13.10 seconds.\n",
      "Waiting for 5.84 seconds.\n",
      "Waiting for 12.70 seconds.\n"
     ]
    }
   ],
   "source": [
    "convention_text = dict()\n",
    "\n",
    "for party in convention_pages :\n",
    "    for link in convention_pages[party] : \n",
    "        r = requests.get(link)\n",
    "        output_file_name = generate_filename_from_url(link)\n",
    "        \n",
    "        link_name = output_file_name[37:]\n",
    "        # pull the page \n",
    "        for link in convention_pages :\n",
    "            try :\n",
    "                r = requests.get(link)\n",
    "            except :\n",
    "                pass \n",
    "    \n",
    "            if r.status_code == 200 :\n",
    "                soup = BeautifulSoup(r.text, 'html.parser')\n",
    "                texts = soup.findAll(text=True)\n",
    "                visible_texts = filter(tag_visible, texts) \n",
    "                convention_text[link] = \" \".join(t.strip() for t in visible_texts)\n",
    "            else :\n",
    "                print(f\"We got code {r.status_code} for this link: {link}\")   \n",
    "            \n",
    "        #process the page    \n",
    "        \n",
    "        \n",
    "        with open(output_file_name,'w',encoding = \"UTF-8\") as outfile :\n",
    "            outfile.write(\"\\t\".join([\"link\",\"text\"]) + \"\\n\")\n",
    "            for link in convention_text :\n",
    "                the_text = convention_text[link]\n",
    "        \n",
    "        # get rid of some of our more annoying output chars\n",
    "                the_text = the_text.replace(\"\\t\",\" \").replace(\"\\n\",\" \").replace(\"\\r\",\" \") \n",
    "        \n",
    "                if not link :\n",
    "                    link = \"empty link\"\n",
    "        \n",
    "                if the_text : # test to see if it is non-empty\n",
    "                    outfile.write(\"\\t\".join([link,the_text]) + \"\\n\")\n",
    "        \n",
    "        # Pause for a bit\n",
    "        wait_time = 5 + random()*10\n",
    "        print(f\"Waiting for {wait_time:.02f} seconds.\")\n",
    "        \n",
    "        sleep(wait_time)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "### A Helpful Function\n",
    "\n",
    "When you have to write out a long string, it's nice to wrap that text. The library `textwrap` makes that easy. The code below generates a long string and writes out the output in wrapped form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices, seed\n",
    "from string import ascii_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a long string with some spaces. \n",
    "\n",
    "string_length = 50000\n",
    "chars_to_sample = ascii_letters + \" \"*8 # Get some spaces in there\n",
    "\n",
    "seed(20200916)\n",
    "\n",
    "text = \"\".join(choices(chars_to_sample,k=string_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll just write out the text. You'll notice it's just one long line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"text.txt\",'w') as outfile :\n",
    "    outfile.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library `textwrap` will let us make a nice, wrapped output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_text = textwrap.wrap(text)\n",
    "\n",
    "with open(\"text_wrapped.txt\",'w') as outfile :\n",
    "    for piece in wrapped_text :\n",
    "        outfile.write(piece + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
